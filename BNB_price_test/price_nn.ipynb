{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 13:47:07.478811: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-15 13:47:07.480858: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-15 13:47:07.501880: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-15 13:47:07.501892: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-15 13:47:07.502444: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-15 13:47:07.506654: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-15 13:47:07.507037: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-15 13:47:07.905858: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_moving_averages(df, window_sizes):\n",
    "    for window_size in window_sizes:\n",
    "        column_name = f'MA_{window_size}'\n",
    "        df[column_name] = df['close'].rolling(window=window_size).mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bnb_historical_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [7, 25, 99, 150]\n",
    "df = calculate_moving_averages(df, window_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[['MA_7', 'MA_25', 'MA_99', 'MA_150' ,'close']].dropna()\n",
    "target = features['close'].values.reshape(-1, 1)\n",
    "features = features.values\n",
    "\n",
    "# Normalize features using Min-Max scaling\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "features_scaled = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28770732, 0.28649775, 0.28619765, 0.28658882, 0.29124236],\n",
       "       [0.28770732, 0.28647033, 0.28618375, 0.28655662, 0.29124236],\n",
       "       [0.28770732, 0.28644291, 0.28616986, 0.28652442, 0.29124236],\n",
       "       ...,\n",
       "       [0.72946341, 0.73064056, 0.72242448, 0.72208092, 0.73183978],\n",
       "       [0.72936585, 0.73061314, 0.72259817, 0.72211772, 0.73183978],\n",
       "       [0.72995122, 0.73050346, 0.72277881, 0.72215451, 0.73251867]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, target, sequence_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        seq = data[i:i + sequence_length]\n",
    "        label = target[i + sequence_length]\n",
    "        sequences.append(seq)\n",
    "        labels.append(label)\n",
    "    return np.array(sequences), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 20  # Adjust as needed\n",
    "X, y = create_sequences(features_scaled, target, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=100, activation='relu', input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Second LSTM layer\n",
    "model.add(LSTM(units=150, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Third LSTM layer\n",
    "model.add(LSTM(units=200, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Dense layer\n",
    "model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "14789/14789 [==============================] - 300s 20ms/step - loss: 2249.7756 - val_loss: 104.5454\n",
      "Epoch 2/50\n",
      "14789/14789 [==============================] - 302s 20ms/step - loss: 91.1455 - val_loss: 118.1755\n",
      "Epoch 3/50\n",
      "14789/14789 [==============================] - 304s 21ms/step - loss: 83.2149 - val_loss: 99.3659\n",
      "Epoch 4/50\n",
      "14789/14789 [==============================] - 302s 20ms/step - loss: 86.8899 - val_loss: 88.6161\n",
      "Epoch 5/50\n",
      "14789/14789 [==============================] - 299s 20ms/step - loss: 105.2899 - val_loss: 134.0544\n",
      "Epoch 6/50\n",
      "14789/14789 [==============================] - 298s 20ms/step - loss: 94.9094 - val_loss: 178.4505\n",
      "Epoch 7/50\n",
      "14789/14789 [==============================] - 297s 20ms/step - loss: 95.2542 - val_loss: 90.4771\n",
      "Epoch 8/50\n",
      "14789/14789 [==============================] - 296s 20ms/step - loss: 562.7490 - val_loss: 848.5389\n",
      "Epoch 9/50\n",
      "14789/14789 [==============================] - 297s 20ms/step - loss: 1024.7324 - val_loss: 689.9996\n",
      "Epoch 10/50\n",
      "14789/14789 [==============================] - 295s 20ms/step - loss: 1287.6613 - val_loss: 2052.4468\n",
      "Epoch 11/50\n",
      "14789/14789 [==============================] - 296s 20ms/step - loss: 1644.5668 - val_loss: 9534.2861\n",
      "Epoch 12/50\n",
      "14789/14789 [==============================] - 295s 20ms/step - loss: 1483.8414 - val_loss: 4749.6177\n",
      "Epoch 13/50\n",
      "14789/14789 [==============================] - 293s 20ms/step - loss: 1362.4832 - val_loss: 234904.5625\n",
      "Epoch 14/50\n",
      "14789/14789 [==============================] - 292s 20ms/step - loss: 1125.8900 - val_loss: 603.4802\n",
      "Epoch 15/50\n",
      "14789/14789 [==============================] - 292s 20ms/step - loss: 1010.1854 - val_loss: 627888.0000\n",
      "Epoch 16/50\n",
      "14789/14789 [==============================] - 292s 20ms/step - loss: 1325.1135 - val_loss: 38046828.0000\n",
      "Epoch 17/50\n",
      "14789/14789 [==============================] - 291s 20ms/step - loss: 1089.6285 - val_loss: 558.0685\n",
      "Epoch 18/50\n",
      "14789/14789 [==============================] - 291s 20ms/step - loss: 1025.4503 - val_loss: 1498.6465\n",
      "Epoch 19/50\n",
      "14789/14789 [==============================] - 296s 20ms/step - loss: 1072.2308 - val_loss: 593.8627\n",
      "Epoch 20/50\n",
      "14789/14789 [==============================] - 298s 20ms/step - loss: 888.6455 - val_loss: 308521.4688\n",
      "Epoch 21/50\n",
      "14789/14789 [==============================] - 298s 20ms/step - loss: 857.3666 - val_loss: 281.5461\n",
      "Epoch 22/50\n",
      "14789/14789 [==============================] - 300s 20ms/step - loss: 655.9494 - val_loss: 265.0121\n",
      "Epoch 23/50\n",
      "14789/14789 [==============================] - 296s 20ms/step - loss: 846.2108 - val_loss: 646.5084\n",
      "Epoch 24/50\n",
      "14789/14789 [==============================] - 290s 20ms/step - loss: 936.4016 - val_loss: 487.5592\n",
      "Epoch 25/50\n",
      "14789/14789 [==============================] - 298s 20ms/step - loss: 657.5164 - val_loss: 248.0219\n",
      "Epoch 26/50\n",
      "14789/14789 [==============================] - 299s 20ms/step - loss: 642.8732 - val_loss: 264.0151\n",
      "Epoch 27/50\n",
      "14789/14789 [==============================] - 299s 20ms/step - loss: 484.1078 - val_loss: 165.4881\n",
      "Epoch 28/50\n",
      "14789/14789 [==============================] - 297s 20ms/step - loss: 586.9453 - val_loss: nan\n",
      "Epoch 29/50\n",
      "14789/14789 [==============================] - 301s 20ms/step - loss: 714.6230 - val_loss: nan\n",
      "Epoch 30/50\n",
      "14789/14789 [==============================] - 303s 20ms/step - loss: 647.0447 - val_loss: nan\n",
      "Epoch 31/50\n",
      "14789/14789 [==============================] - 303s 21ms/step - loss: 570.3535 - val_loss: nan\n",
      "Epoch 32/50\n",
      "14789/14789 [==============================] - 301s 20ms/step - loss: 426.9103 - val_loss: nan\n",
      "Epoch 33/50\n",
      "14789/14789 [==============================] - 300s 20ms/step - loss: 531.9391 - val_loss: nan\n",
      "Epoch 34/50\n",
      "14789/14789 [==============================] - 300s 20ms/step - loss: 517.8554 - val_loss: nan\n",
      "Epoch 35/50\n",
      "14789/14789 [==============================] - 299s 20ms/step - loss: 374.4620 - val_loss: nan\n",
      "Epoch 36/50\n",
      "14789/14789 [==============================] - 295s 20ms/step - loss: 300.9926 - val_loss: nan\n",
      "Epoch 37/50\n",
      "14789/14789 [==============================] - 288s 19ms/step - loss: 348.3026 - val_loss: nan\n",
      "Epoch 38/50\n",
      "14789/14789 [==============================] - 288s 19ms/step - loss: 385.8581 - val_loss: nan\n",
      "Epoch 39/50\n",
      "14789/14789 [==============================] - 288s 19ms/step - loss: 381.8013 - val_loss: nan\n",
      "Epoch 40/50\n",
      "14789/14789 [==============================] - 288s 19ms/step - loss: 344.1349 - val_loss: nan\n",
      "Epoch 41/50\n",
      "14789/14789 [==============================] - 288s 19ms/step - loss: 336.2820 - val_loss: nan\n",
      "Epoch 42/50\n",
      "14789/14789 [==============================] - 288s 19ms/step - loss: 359.2703 - val_loss: nan\n",
      "Epoch 43/50\n",
      "14789/14789 [==============================] - 287s 19ms/step - loss: 380.7270 - val_loss: nan\n",
      "Epoch 44/50\n",
      "14789/14789 [==============================] - 287s 19ms/step - loss: 349.7527 - val_loss: nan\n",
      "Epoch 45/50\n",
      "14789/14789 [==============================] - 288s 19ms/step - loss: 391.5921 - val_loss: nan\n",
      "Epoch 46/50\n",
      "14789/14789 [==============================] - 288s 19ms/step - loss: 371.0355 - val_loss: nan\n",
      "Epoch 47/50\n",
      "14789/14789 [==============================] - 288s 19ms/step - loss: 380.5425 - val_loss: nan\n",
      "Epoch 48/50\n",
      "14789/14789 [==============================] - 295s 20ms/step - loss: 489.7774 - val_loss: nan\n",
      "Epoch 49/50\n",
      "14789/14789 [==============================] - 295s 20ms/step - loss: 430.2802 - val_loss: nan\n",
      "Epoch 50/50\n",
      "14789/14789 [==============================] - 295s 20ms/step - loss: 420.2410 - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f9889fa08e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=50, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trained_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_24 = pd.read_csv('bnb_historical_data_24.csv')\n",
    "\n",
    "combined_data = pd.concat([df, df_24], axis=0, ignore_index=True)\n",
    "combined_data = combined_data.drop_duplicates(subset='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [7, 25, 99, 150]\n",
    "combined_data = calculate_moving_averages(combined_data, window_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_24 = combined_data[['MA_7', 'MA_25', 'MA_99', 'MA_150' ,'close']].dropna()\n",
    "target_24 = features_24['close'].values.reshape(-1, 1)\n",
    "ploting = combined_data.dropna()\n",
    "features_24 = features_24.values\n",
    "\n",
    "features_scaled_24 = scaler.fit_transform(features_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 20  # Adjust as needed\n",
    "X_24, y_24 = create_sequences(features_scaled_24, target_24, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19011/19011 [==============================] - 137s 7ms/step - loss: nan\n",
      "Mean Squared Error on Test Set: nan\n"
     ]
    }
   ],
   "source": [
    "loss_24 = model.evaluate(X_24, y_24)\n",
    "print(f'Mean Squared Error on Test Set: {loss_24}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19011/19011 [==============================] - 137s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_785830/957016094.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ploting['predictions'] = predictions_df['predictions']\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_24)\n",
    "predictions_df = pd.DataFrame(predictions, columns=['predictions'], index=ploting.index[20:])\n",
    "ploting['predictions'] = predictions_df['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_785830/1498949400.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ploting['timestamp'] = pd.to_datetime(ploting['timestamp'])\n"
     ]
    }
   ],
   "source": [
    "ploting['timestamp'] = pd.to_datetime(ploting['timestamp']) \n",
    "desired_months = [1, 2, 3]  # January, February, and March\n",
    "filtered_df = ploting[ploting['timestamp'].dt.month.isin(desired_months)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_get</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>close_time</th>\n",
       "      <th>quote_asset_volume</th>\n",
       "      <th>number_of_trades</th>\n",
       "      <th>taker_buy_base_asset_volume</th>\n",
       "      <th>taker_buy_quote_asset_volume</th>\n",
       "      <th>ignore</th>\n",
       "      <th>MA_7</th>\n",
       "      <th>MA_25</th>\n",
       "      <th>MA_99</th>\n",
       "      <th>MA_150</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>149</td>\n",
       "      <td>2023-01-01 02:29:00</td>\n",
       "      <td>245.6</td>\n",
       "      <td>245.7</td>\n",
       "      <td>245.6</td>\n",
       "      <td>245.6</td>\n",
       "      <td>14.667</td>\n",
       "      <td>1672540199999</td>\n",
       "      <td>3602.4533</td>\n",
       "      <td>26</td>\n",
       "      <td>2.381</td>\n",
       "      <td>585.0117</td>\n",
       "      <td>0</td>\n",
       "      <td>245.628571</td>\n",
       "      <td>245.640</td>\n",
       "      <td>245.746465</td>\n",
       "      <td>245.900667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>150</td>\n",
       "      <td>2023-01-01 02:30:00</td>\n",
       "      <td>245.7</td>\n",
       "      <td>245.7</td>\n",
       "      <td>245.6</td>\n",
       "      <td>245.6</td>\n",
       "      <td>36.024</td>\n",
       "      <td>1672540259999</td>\n",
       "      <td>8850.2972</td>\n",
       "      <td>46</td>\n",
       "      <td>28.028</td>\n",
       "      <td>6886.4796</td>\n",
       "      <td>0</td>\n",
       "      <td>245.628571</td>\n",
       "      <td>245.636</td>\n",
       "      <td>245.744444</td>\n",
       "      <td>245.896000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>151</td>\n",
       "      <td>2023-01-01 02:31:00</td>\n",
       "      <td>245.7</td>\n",
       "      <td>245.7</td>\n",
       "      <td>245.5</td>\n",
       "      <td>245.6</td>\n",
       "      <td>131.485</td>\n",
       "      <td>1672540319999</td>\n",
       "      <td>32290.1783</td>\n",
       "      <td>93</td>\n",
       "      <td>47.906</td>\n",
       "      <td>11765.8213</td>\n",
       "      <td>0</td>\n",
       "      <td>245.628571</td>\n",
       "      <td>245.632</td>\n",
       "      <td>245.742424</td>\n",
       "      <td>245.891333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>152</td>\n",
       "      <td>2023-01-01 02:32:00</td>\n",
       "      <td>245.6</td>\n",
       "      <td>245.7</td>\n",
       "      <td>245.5</td>\n",
       "      <td>245.6</td>\n",
       "      <td>68.648</td>\n",
       "      <td>1672540379999</td>\n",
       "      <td>16859.3951</td>\n",
       "      <td>67</td>\n",
       "      <td>60.975</td>\n",
       "      <td>14975.6186</td>\n",
       "      <td>0</td>\n",
       "      <td>245.628571</td>\n",
       "      <td>245.632</td>\n",
       "      <td>245.739394</td>\n",
       "      <td>245.887333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>153</td>\n",
       "      <td>2023-01-01 02:33:00</td>\n",
       "      <td>245.7</td>\n",
       "      <td>245.8</td>\n",
       "      <td>245.6</td>\n",
       "      <td>245.8</td>\n",
       "      <td>149.291</td>\n",
       "      <td>1672540439999</td>\n",
       "      <td>36687.2963</td>\n",
       "      <td>64</td>\n",
       "      <td>149.230</td>\n",
       "      <td>36672.3147</td>\n",
       "      <td>0</td>\n",
       "      <td>245.657143</td>\n",
       "      <td>245.636</td>\n",
       "      <td>245.737374</td>\n",
       "      <td>245.886000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>244</td>\n",
       "      <td>2023-01-01 04:04:00</td>\n",
       "      <td>245.2</td>\n",
       "      <td>245.3</td>\n",
       "      <td>245.1</td>\n",
       "      <td>245.1</td>\n",
       "      <td>77.485</td>\n",
       "      <td>1672545899999</td>\n",
       "      <td>18995.4326</td>\n",
       "      <td>68</td>\n",
       "      <td>23.791</td>\n",
       "      <td>5833.5976</td>\n",
       "      <td>0</td>\n",
       "      <td>245.257143</td>\n",
       "      <td>245.272</td>\n",
       "      <td>245.372727</td>\n",
       "      <td>245.476667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>245</td>\n",
       "      <td>2023-01-01 04:05:00</td>\n",
       "      <td>245.1</td>\n",
       "      <td>245.2</td>\n",
       "      <td>245.1</td>\n",
       "      <td>245.1</td>\n",
       "      <td>109.263</td>\n",
       "      <td>1672545959999</td>\n",
       "      <td>26780.5882</td>\n",
       "      <td>51</td>\n",
       "      <td>2.269</td>\n",
       "      <td>556.3588</td>\n",
       "      <td>0</td>\n",
       "      <td>245.228571</td>\n",
       "      <td>245.268</td>\n",
       "      <td>245.367677</td>\n",
       "      <td>245.473333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>246</td>\n",
       "      <td>2023-01-01 04:06:00</td>\n",
       "      <td>245.1</td>\n",
       "      <td>245.2</td>\n",
       "      <td>245.1</td>\n",
       "      <td>245.2</td>\n",
       "      <td>25.128</td>\n",
       "      <td>1672546019999</td>\n",
       "      <td>6159.7923</td>\n",
       "      <td>34</td>\n",
       "      <td>9.195</td>\n",
       "      <td>2254.6140</td>\n",
       "      <td>0</td>\n",
       "      <td>245.214286</td>\n",
       "      <td>245.268</td>\n",
       "      <td>245.362626</td>\n",
       "      <td>245.470000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>247</td>\n",
       "      <td>2023-01-01 04:07:00</td>\n",
       "      <td>245.2</td>\n",
       "      <td>245.2</td>\n",
       "      <td>245.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>154.438</td>\n",
       "      <td>1672546079999</td>\n",
       "      <td>37845.6339</td>\n",
       "      <td>65</td>\n",
       "      <td>18.458</td>\n",
       "      <td>4524.7649</td>\n",
       "      <td>0</td>\n",
       "      <td>245.171429</td>\n",
       "      <td>245.256</td>\n",
       "      <td>245.355556</td>\n",
       "      <td>245.466667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>248</td>\n",
       "      <td>2023-01-01 04:08:00</td>\n",
       "      <td>245.0</td>\n",
       "      <td>245.1</td>\n",
       "      <td>244.8</td>\n",
       "      <td>244.9</td>\n",
       "      <td>720.563</td>\n",
       "      <td>1672546139999</td>\n",
       "      <td>176510.8311</td>\n",
       "      <td>318</td>\n",
       "      <td>170.660</td>\n",
       "      <td>41799.9770</td>\n",
       "      <td>0</td>\n",
       "      <td>245.128571</td>\n",
       "      <td>245.240</td>\n",
       "      <td>245.348485</td>\n",
       "      <td>245.462000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index_get           timestamp   open   high    low  close   volume  \\\n",
       "149        149 2023-01-01 02:29:00  245.6  245.7  245.6  245.6   14.667   \n",
       "150        150 2023-01-01 02:30:00  245.7  245.7  245.6  245.6   36.024   \n",
       "151        151 2023-01-01 02:31:00  245.7  245.7  245.5  245.6  131.485   \n",
       "152        152 2023-01-01 02:32:00  245.6  245.7  245.5  245.6   68.648   \n",
       "153        153 2023-01-01 02:33:00  245.7  245.8  245.6  245.8  149.291   \n",
       "..         ...                 ...    ...    ...    ...    ...      ...   \n",
       "244        244 2023-01-01 04:04:00  245.2  245.3  245.1  245.1   77.485   \n",
       "245        245 2023-01-01 04:05:00  245.1  245.2  245.1  245.1  109.263   \n",
       "246        246 2023-01-01 04:06:00  245.1  245.2  245.1  245.2   25.128   \n",
       "247        247 2023-01-01 04:07:00  245.2  245.2  245.0  245.0  154.438   \n",
       "248        248 2023-01-01 04:08:00  245.0  245.1  244.8  244.9  720.563   \n",
       "\n",
       "        close_time  quote_asset_volume  number_of_trades  \\\n",
       "149  1672540199999           3602.4533                26   \n",
       "150  1672540259999           8850.2972                46   \n",
       "151  1672540319999          32290.1783                93   \n",
       "152  1672540379999          16859.3951                67   \n",
       "153  1672540439999          36687.2963                64   \n",
       "..             ...                 ...               ...   \n",
       "244  1672545899999          18995.4326                68   \n",
       "245  1672545959999          26780.5882                51   \n",
       "246  1672546019999           6159.7923                34   \n",
       "247  1672546079999          37845.6339                65   \n",
       "248  1672546139999         176510.8311               318   \n",
       "\n",
       "     taker_buy_base_asset_volume  taker_buy_quote_asset_volume  ignore  \\\n",
       "149                        2.381                      585.0117       0   \n",
       "150                       28.028                     6886.4796       0   \n",
       "151                       47.906                    11765.8213       0   \n",
       "152                       60.975                    14975.6186       0   \n",
       "153                      149.230                    36672.3147       0   \n",
       "..                           ...                           ...     ...   \n",
       "244                       23.791                     5833.5976       0   \n",
       "245                        2.269                      556.3588       0   \n",
       "246                        9.195                     2254.6140       0   \n",
       "247                       18.458                     4524.7649       0   \n",
       "248                      170.660                    41799.9770       0   \n",
       "\n",
       "           MA_7    MA_25       MA_99      MA_150  predictions  \n",
       "149  245.628571  245.640  245.746465  245.900667          NaN  \n",
       "150  245.628571  245.636  245.744444  245.896000          NaN  \n",
       "151  245.628571  245.632  245.742424  245.891333          NaN  \n",
       "152  245.628571  245.632  245.739394  245.887333          NaN  \n",
       "153  245.657143  245.636  245.737374  245.886000          NaN  \n",
       "..          ...      ...         ...         ...          ...  \n",
       "244  245.257143  245.272  245.372727  245.476667          NaN  \n",
       "245  245.228571  245.268  245.367677  245.473333          NaN  \n",
       "246  245.214286  245.268  245.362626  245.470000          NaN  \n",
       "247  245.171429  245.256  245.355556  245.466667          NaN  \n",
       "248  245.128571  245.240  245.348485  245.462000          NaN  \n",
       "\n",
       "[100 rows x 18 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "candlestick_trace  = go.Candlestick(x=filtered_df['timestamp'],\n",
    "                open=filtered_df['open'],\n",
    "                high=filtered_df['high'],\n",
    "                low=filtered_df['low'],\n",
    "                close=filtered_df['close'])\n",
    "\n",
    "symbol = 'BNBUSDT'\n",
    "\n",
    "trace_ma_7 = go.Scatter(x=filtered_df['timestamp'], y=filtered_df['MA_7'], mode='lines', name='MA(7)', line=dict(color='green', dash='dash'))\n",
    "trace_ma_25 = go.Scatter(x=filtered_df['timestamp'], y=filtered_df['MA_25'], mode='lines', name='MA(25)', line=dict(color='red', dash='dash'))\n",
    "trace_ma_99 = go.Scatter(x=filtered_df['timestamp'], y=filtered_df['MA_99'], mode='lines', name='MA(99)', line=dict(color='purple', dash='dash'))\n",
    "\n",
    "pred = go.Scatter(x=filtered_df['timestamp'], y=filtered_df['predictions'], mode='lines', name='predicted-price', line=dict(color='blue'))\n",
    "\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[candlestick_trace, trace_ma_7, trace_ma_25, trace_ma_99, pred])\n",
    "\n",
    "fig.update_layout(title=f'Historical Price Data for {symbol}',\n",
    "                  xaxis_title='Timestamp',\n",
    "                  yaxis_title='Price (USDT)',\n",
    "                  xaxis_rangeslider_visible=False)\n",
    "\n",
    "# Show the interactive plot in a browser\n",
    "fig.write_html('plot.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
